Human-Centered Artificial Intelligence: Reliable, Safe and Trustworthy (2020)
--
Ben Shneiderman, University of Maryland
<br>
Source: https://arxiv.org/pdf/2002.04087.pdf

Abstract
--
Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility. 

Human Control vs Computer Automation: One-Dimensional
--
<img width="1151" alt="스크린샷 2021-06-15 오후 1 11 05" src="https://user-images.githubusercontent.com/38929910/121991711-32475680-cddb-11eb-9829-de1d1f76ab43.png">

Human Control vs Computer Automation: Two-Dimensional
--
<img width="1062" alt="스크린샷 2021-06-15 오후 1 11 42" src="https://user-images.githubusercontent.com/38929910/121991748-455a2680-cddb-11eb-968c-9bf274bba7c4.png">

Discussion
--
- Is the problem space only applicable to certain cases where we design for specific human control-able scenarios?
- How do we address human control for natural language conversational agents? (e.g. Google's LAMBDA)
- How do we ensure transparency and controllability of black box technologies?
